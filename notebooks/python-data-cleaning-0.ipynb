{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ef0a57-395a-40a5-ae23-064448fac911",
   "metadata": {},
   "source": [
    "# Pythonic Data Cleaning With pandas and NumPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e7251e-b8b7-4efc-8890-bc22f69529e8",
   "metadata": {},
   "source": [
    "## prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da1fbb7d-8e4f-4232-9914-ac58b1131745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import os\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "import json\n",
    "import pickle\n",
    "import six\n",
    "import charset_normalizer\n",
    "from wordcloud import WordCloud \n",
    "\n",
    "sns.set()\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26124d94-854d-4430-9a82-65014c44fabc",
   "metadata": {},
   "source": [
    "### Dropping Columns in a DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9a06f-8b42-48da-8f17-bf42f811ed53",
   "metadata": {},
   "source": [
    "Often, you’ll find that not all the categories of data in a dataset are useful to you. For example, you might have a dataset containing student information (name, grade, standard, parents’ names, and address) but want to focus on analyzing student grades.\n",
    "\n",
    "In this case, the address or parents’ names categories are not important to you. Retaining these unneeded categories will take up unnecessary space and potentially also bog down runtime.\n",
    "\n",
    "pandas provides a handy way of removing unwanted columns or rows from a DataFrame with the drop() function. Let’s look at a simple example where we drop a number of columns from a DataFrame.\n",
    "\n",
    "First, let’s create a DataFrame out of the CSV file ‘BL-Flickr-Images-Book.csv’. In the examples below, we pass a relative path to pd.read_csv, meaning that all of the datasets are in a folder named Datasets in our current working directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b8be1-2f5e-4d8a-a17e-971cbb267b54",
   "metadata": {},
   "source": [
    "### storage init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f11a9a8d-9c44-41d9-9c26-74ec48f2a8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-set-0/\n",
      "data-set-0/BL-Flickr-Images-Book.csv\n",
      "data-set-0/olympics.csv\n",
      "data-set-0/university_towns.txt\n"
     ]
    }
   ],
   "source": [
    "storage_client =  storage.Client.from_service_account_json('heidless-jupyter-0-d2008100d98c.json')\n",
    "\n",
    "BUCKET_NAME = 'python-data-cleaning-0'\n",
    "\n",
    "bucket = storage_client.get_bucket(BUCKET_NAME)\n",
    "\n",
    "file_names = list(bucket.list_blobs(prefix=''))\n",
    "for name in file_names:\n",
    "    print(name.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0696e-07a0-423c-a8dd-bd351d6e782a",
   "metadata": {},
   "source": [
    "### read file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef333b28-b323-4dcf-90ff-5c9bc159f840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_file: data-set-0/BL-Flickr-Images-Book.csv\n",
      "data-set-0/BL-Flickr-Images-Book.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data-set-0/BL-Flickr-Images-Book.csv']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "AllCSV = []\n",
    "my_prefix = 'data-set-0/'\n",
    "my_file = 'BL-Flickr-Images-Book.csv'\n",
    "full_file = my_prefix + my_file\n",
    "print(f'full_file: {full_file}')\n",
    "\n",
    "file_names = list(bucket.list_blobs(prefix=my_prefix))\n",
    "for file in file_names:\n",
    "    if(file.name != my_prefix):\n",
    "        if file.name == full_file:\n",
    "            AllCSV.append(file.name)\n",
    "            print(file.name)\n",
    "AllCSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c60fc848-18c8-4540-a54e-57e2be37cabf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(s, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISO-8859-1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m#df['country'] = csv[0:2] # adding column 'country' so that each dataset could be identified uniquely\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m         \u001b[43mall_dataframes\u001b[49m\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(csv)\n\u001b[1;32m     15\u001b[0m all_dataframes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhead() \u001b[38;5;66;03m# index 0 to 9 for [CA, DE, FR, GB, IN, JP, KR, MX, RU, US] datasets\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_dataframes' is not defined"
     ]
    }
   ],
   "source": [
    "all_dataframes = []\n",
    "#file_name = f'json/CA_category_id.json'\n",
    "\n",
    "for csv in AllCSV:\n",
    "    blob = bucket.get_blob(csv)\n",
    "    if blob is not None and blob.exists(storage_client):\n",
    "        bt = blob.download_as_string()\n",
    "        s = str(bt, 'ISO-8859-1')\n",
    "        s = StringIO(s)\n",
    "        df = pd.read_csv(s, encoding='ISO-8859-1')\n",
    "        #df['country'] = csv[0:2] # adding column 'country' so that each dataset could be identified uniquely\n",
    "        all_dataframes.append(df)\n",
    "        print(csv)\n",
    "    \n",
    "all_dataframes[0].head() # index 0 to 9 for [CA, DE, FR, GB, IN, JP, KR, MX, RU, US] datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "eb7e5eaa-69af-497a-aae1-f8bf621764a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['Edition Statement',\n",
    "           'Corporate Author',\n",
    "           'Corporate Contributors',\n",
    "           'Former owner',\n",
    "           'Engraver',\n",
    "           'Contributors',\n",
    "           'Issuance type',\n",
    "           'Shelfmarks']\n",
    "\n",
    "df.drop(to_drop, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e5283-40f1-4bcd-afeb-1e550c7ba5b5",
   "metadata": {},
   "source": [
    "Above, we defined a list that contains the names of all the columns we want to drop. Next, we call the drop() function on our object, passing in the inplace parameter as True and the axis parameter as 1. This tells pandas that we want the changes to be made directly in our object and that it should look for the values to be dropped in the columns of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9c214934-e3af-4fb6-9308-03a7bed57979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Place of Publication</th>\n",
       "      <th>Date of Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Flickr URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206</td>\n",
       "      <td>London</td>\n",
       "      <td>1879 [1878]</td>\n",
       "      <td>S. Tinsley &amp; Co.</td>\n",
       "      <td>Walter Forbes. [A novel.] By A. A</td>\n",
       "      <td>A. A.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216</td>\n",
       "      <td>London; Virtue &amp; Yorston</td>\n",
       "      <td>1868</td>\n",
       "      <td>Virtue &amp; Co.</td>\n",
       "      <td>All for Greed. [A novel. The dedication signed...</td>\n",
       "      <td>A., A. A.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218</td>\n",
       "      <td>London</td>\n",
       "      <td>1869</td>\n",
       "      <td>Bradbury, Evans &amp; Co.</td>\n",
       "      <td>Love the Avenger. By the author of âAll for ...</td>\n",
       "      <td>A., A. A.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identifier      Place of Publication Date of Publication  \\\n",
       "0         206                    London         1879 [1878]   \n",
       "1         216  London; Virtue & Yorston                1868   \n",
       "2         218                    London                1869   \n",
       "\n",
       "               Publisher                                              Title  \\\n",
       "0       S. Tinsley & Co.                  Walter Forbes. [A novel.] By A. A   \n",
       "1           Virtue & Co.  All for Greed. [A novel. The dedication signed...   \n",
       "2  Bradbury, Evans & Co.  Love the Avenger. By the author of âAll for ...   \n",
       "\n",
       "      Author                                         Flickr URL  \n",
       "0      A. A.  http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "1  A., A. A.  http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "2  A., A. A.  http://www.flickr.com/photos/britishlibrary/ta...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536559d5-df53-4555-8f33-2a4c0088a7af",
   "metadata": {},
   "source": [
    "Alternatively, we could also remove the columns by passing them to the columns parameter directly instead of separately specifying the labels to be removed and the axis where pandas should look for the labels:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d6bdaa-5db1-48ac-aef0-759046cf67bb",
   "metadata": {},
   "source": [
    "df.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb3f5e-b7ac-47ed-b919-2a6cc5439f14",
   "metadata": {},
   "source": [
    "### Changing the Index of a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf7dbb7-05fc-4990-a938-a597a8e1b3c4",
   "metadata": {},
   "source": [
    "A pandas Index extends the functionality of NumPy arrays to allow for more versatile slicing and labeling. In many cases, it is helpful to use a uniquely valued identifying field of the data as its index.\n",
    "\n",
    "For example, in the dataset used in the previous section, it can be expected that when a librarian searches for a record, they may input the unique identifier (values in the Identifier column) for a book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c252f7ea-1945-44b4-a1b3-7dd96ed74966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Identifier'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "abab311a-1904-4515-a980-7372339ed67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place of Publication</th>\n",
       "      <th>Date of Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Flickr URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>London</td>\n",
       "      <td>1879 [1878]</td>\n",
       "      <td>S. Tinsley &amp; Co.</td>\n",
       "      <td>Walter Forbes. [A novel.] By A. A</td>\n",
       "      <td>A. A.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>London; Virtue &amp; Yorston</td>\n",
       "      <td>1868</td>\n",
       "      <td>Virtue &amp; Co.</td>\n",
       "      <td>All for Greed. [A novel. The dedication signed...</td>\n",
       "      <td>A., A. A.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>London</td>\n",
       "      <td>1869</td>\n",
       "      <td>Bradbury, Evans &amp; Co.</td>\n",
       "      <td>Love the Avenger. By the author of âAll for ...</td>\n",
       "      <td>A., A. A.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>London</td>\n",
       "      <td>1851</td>\n",
       "      <td>James Darling</td>\n",
       "      <td>Welsh Sketches, chiefly ecclesiastical, to the...</td>\n",
       "      <td>A., E. S.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>London</td>\n",
       "      <td>1857</td>\n",
       "      <td>Wertheim &amp; Macintosh</td>\n",
       "      <td>[The World in which I live, and my place in it...</td>\n",
       "      <td>A., E. S.</td>\n",
       "      <td>http://www.flickr.com/photos/britishlibrary/ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Place of Publication Date of Publication  \\\n",
       "Identifier                                                 \n",
       "206                           London         1879 [1878]   \n",
       "216         London; Virtue & Yorston                1868   \n",
       "218                           London                1869   \n",
       "472                           London                1851   \n",
       "480                           London                1857   \n",
       "\n",
       "                        Publisher  \\\n",
       "Identifier                          \n",
       "206              S. Tinsley & Co.   \n",
       "216                  Virtue & Co.   \n",
       "218         Bradbury, Evans & Co.   \n",
       "472                 James Darling   \n",
       "480          Wertheim & Macintosh   \n",
       "\n",
       "                                                        Title     Author  \\\n",
       "Identifier                                                                 \n",
       "206                         Walter Forbes. [A novel.] By A. A      A. A.   \n",
       "216         All for Greed. [A novel. The dedication signed...  A., A. A.   \n",
       "218         Love the Avenger. By the author of âAll for ...  A., A. A.   \n",
       "472         Welsh Sketches, chiefly ecclesiastical, to the...  A., E. S.   \n",
       "480         [The World in which I live, and my place in it...  A., E. S.   \n",
       "\n",
       "                                                   Flickr URL  \n",
       "Identifier                                                     \n",
       "206         http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "216         http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "218         http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "472         http://www.flickr.com/photos/britishlibrary/ta...  \n",
       "480         http://www.flickr.com/photos/britishlibrary/ta...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df.set_index('Identifier')\n",
    "df.set_index('Identifier', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e783c14-bced-425d-b551-66561455f4b0",
   "metadata": {},
   "source": [
    "We can access each record in a straightforward way with `loc[]`. Although loc[] may not have all that intuitive of a name, it allows us to do label-based indexing, which is the labeling of a row or record without regard to its position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "85f3e239-de6c-4dcd-981d-1d8071e692f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Place of Publication                                               London\n",
       "Date of Publication                                           1879 [1878]\n",
       "Publisher                                                S. Tinsley & Co.\n",
       "Title                                   Walter Forbes. [A novel.] By A. A\n",
       "Author                                                              A. A.\n",
       "Flickr URL              http://www.flickr.com/photos/britishlibrary/ta...\n",
       "Name: 206, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[206]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ccdc8-f8ab-43f0-bfc6-11bcde74bbcc",
   "metadata": {},
   "source": [
    "In other words, 206 is the first label of the index. To access it by position, we could use df.iloc[0], which does position-based indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "39236f5a-e3ea-42bd-8668-28ef12039252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Place of Publication                                               London\n",
       "Date of Publication                                                  1869\n",
       "Publisher                                           Bradbury, Evans & Co.\n",
       "Title                   Love the Avenger. By the author of âAll for ...\n",
       "Author                                                          A., A. A.\n",
       "Flickr URL              http://www.flickr.com/photos/britishlibrary/ta...\n",
       "Name: 218, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b32b4-dc30-4b1b-a60f-4b9c66c0bf82",
   "metadata": {},
   "source": [
    "Previously, our index was a RangeIndex: integers starting from 0, analogous to Python’s built-in range. By passing a column name to set_index, we have changed the index to the values in Identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb98138-59d4-4d8a-9f2e-dfb38a1d3c9e",
   "metadata": {},
   "source": [
    "## Tidying up Fields in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2fa317-1764-4ab3-b43e-142b58cb6954",
   "metadata": {},
   "source": [
    "So far, we have removed unnecessary columns and changed the index of our DataFrame to something more sensible. In this section, we will clean specific columns and get them to a uniform format to get a better understanding of the dataset and enforce consistency. In particular, we will be cleaning Date of Publication and Place of Publication.\n",
    "\n",
    "Upon inspection, all of the data types are currently the object dtype, which is roughly analogous to str in native Python.\n",
    "\n",
    "It encapsulates any field that can’t be neatly fit as numerical or categorical data. This makes sense since we’re working with data that is initially a bunch of messy strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4dfab0fe-dc9d-4756-beb1-76aaf44ed0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "50edc3b1-c77c-4031-97c6-bc192ed53211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identifier\n",
       "1905           1888\n",
       "1929    1839, 38-54\n",
       "2836           1897\n",
       "2854           1865\n",
       "2956        1860-63\n",
       "2957           1873\n",
       "3017           1866\n",
       "3131           1899\n",
       "4598           1814\n",
       "4884           1820\n",
       "Name: Date of Publication, dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1905:, 'Date of Publication'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23044c56-f137-476f-b5ac-7185a941f2bc",
   "metadata": {},
   "source": [
    "A particular book can have only one date of publication. Therefore, we need to do the following:\n",
    "\n",
    "- Remove the extra dates in square brackets, wherever present: 1879 [1878]\n",
    "- Convert date ranges to their “start date”, wherever present: 1860-63; 1839, 38-54\n",
    "- Completely remove the dates we are not certain about and replace them with NumPy’s NaN: [1897?]\n",
    "- Convert the string nan to NumPy’s NaN value\n",
    "Synthesizing these patterns, we can actually take advantage of a single regular expression to extract the publication year:\n",
    "\n",
    "regex = r'^(\\d{4})'\n",
    "\n",
    "The regular expression above is meant to find any four digits at the beginning of a string, which suffices for our case. The above is a raw string (meaning that a backslash is no longer an escape character), which is standard practice with regular expressions.\n",
    "\n",
    "The \\d represents any digit, and {4} repeats this rule four times. The ^ character matches the start of a string, and the parentheses denote a capturing group, which signals to pandas that we want to extract that part of the regex. (We want ^ to avoid cases where [ starts off the string.)\n",
    "\n",
    "Let’s see what happens when we run this regex across our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff9dcd-e3e5-4de7-b0e4-3585ef4247d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
